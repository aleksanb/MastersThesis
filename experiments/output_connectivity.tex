\section{Minimum required output connectivity}

\subsection{Description}

One isn't always able to fully instrument a computational substrate used for reserervoir computing.
While a microelectrode array gives coarse-grained access to smaller substrates than ever,
one is still limited to a number of samples equal to the number of microelectrodes in the array.
Other reasons can include instrumentation being prohibitively expensive,
physically impractical or impossible,
or quantum effects changing the material as one observes it.
These situations result in less internal state and potentially less computational power being exposed to the user.

How does this restricted viewing of the reservoir state affect its predictive behavior?
If there is an interference effect between the unobserved parts of the reservoir,
does this effect increase the computational ability of the observed subset or decrease it?
To test this hypothesis,
chosen subsets of larger reservoirs will be compared to separate reservoirs of that exact size.
This subset should perform better, equal, or worse than the independent reservoir, and therefore answer the hypothesis.

To reduce the search space, only Temporal Parity 3 and 5 will be used for these experiments.
In addition, all reservoirs will have a fixed input connectivity of 50\%,
backed by the findings of optimal IC from the previous section (as summarized in table \ref{tab:accuracy-thresholds}).
Reservoir subsets will be chosen randomly from all available nodes,
which only seems fitting given the random nature of the RBN and the lack of a meaningful physical projection.
The reservoir parameters used for this experiment are shown in table \ref{tab:oc-reservoir-parameters},
with the parameters for Temporal Parity staying the as for the previous experiments (table \ref{tab:tasks}).

\begin{table}[ht]
    \centering
    \caption{Reservoir parameters for optimal output connectivity}
    \label{tab:oc-reservoir-parameters}
    \begin{tabular}{ll}
        \hline
        \textbf{Parameter} & \textbf{Configuration} \\
        \hline
        \hline
        Task                & Temporal Parity 3 and 5        \\
        Nodes               & 10 to (100, 140), step size=10 \\
        Connectivity        & 3                              \\
        Input connectivity  & $ n\_nodes / 2 $               \\
        Subset size         & [0..n\_nodes], step size=10    \\
        Sample size         & 50 \\
        \hline
    \end{tabular}
\end{table}

\subsection{Results}

For easier comparison of the performance of a reservoir subset against reservoirs of that exact size,
plots aggregating the best accuracy distributions for each reservoir size are created.
These are based on the accuracy distribution for the optimal input connectivity for that reservoir size,
as shown in table \ref{tab:chosen-optimal-ic-values} in appendix \ref{app:reservoir_size-input_connectivity}.
These are then compared to the subset-accuracy plots created from the parameters of table \ref{tab:oc-reservoir-parameters}.

Figure \ref{fig:output-connectivity-TP3} shows this comparison for task TP3, up to a reservoir size of 100.
Figure \ref{fig:output-connectivity-TP5} shows the same comparison for task TP5, up to a reservoir size of 140.
The subset-accuracy plots for reservoir sizes $ \le 100 $ and $ \le 140 $ not presented here are shown in figures \ref{fig:TP3-OC-1} through \ref{fig:TP5-OC-2} in appendix \ref{app:minimum_output-connectivity}.

\begin{figure*}[t]
    \centering
    \caption{
        Accuracy plots for task TP3.
        Figure \ref{fig:output-connectivity-TP3-composite} shows the best performing n-sized reservoirs up to a size of 100.
        Figure \ref{fig:output-connectivity-TP3-subset} shows reservoir performance for subsets of reservoirs of size 100.
        All n-sized subsets perform virtually identical to their same-sized reservoirs.
    }
    \label{fig:output-connectivity-TP3}
    \resizebox{\textwidth}{!}{
        \subfloat[Best n-sized reservoir performance on TP3]{
            \input{experiments/results/TP3-IO/boxplot-best-per-size.tex}
            \label{fig:output-connectivity-TP3-composite}
        }
        \subfloat[Reservoir subset performance on TP3]{
            \input{experiments/results/TP3-OC/boxplot-output_connectivity-N100-K3-S50.tex}
            \label{fig:output-connectivity-TP3-subset}
        }
    }
\end{figure*}

\begin{figure*}[t]
    \centering
    \caption{
        Accuracy plots for task TP5.
        Figure \ref{fig:output-connectivity-TP5-composite} shows the best performing n-sized reservoirs up to a size of 140,
        Figure \ref{fig:output-connectivity-TP5-subset} shows reservoir performance for subsets of reservoirs of size 140.
        All n-sized subsets perform virtually identical to their same-sized reservoirs.
    }
    \label{fig:output-connectivity-TP5}
    \resizebox{\textwidth}{!}{
        \subfloat[Best n-sized reservoir performance on TP5]{
            \input{experiments/results/TP5-IO/boxplot-best-per-size.tex}
            \label{fig:output-connectivity-TP5-composite}
        }
        \subfloat[Reservoir subset performance on TP5]{
            \input{experiments/results/TP5-OC/boxplot-N140-K3-S50-output_connectivity.tex}
            \label{fig:output-connectivity-TP5-subset}
        }
    }
\end{figure*}

\subsection{Discussion}

The resulting distributions from reservoir subsets and same-sized reservoirs are extremely similar,
as seen in figures \ref{fig:output-connectivity-TP3} and \ref{fig:output-connectivity-TP5}.
The fact that reservoir subsets perform almost identically to the same-sized subsets indicates that any interference from the unused parts of the reservoir may be minimal.
Additionally, as soon as the reservoir subset size is as large as the minimum required reservoir size,
20 for TP3 and 90-100 for TP5 (table \ref{tab:accuracy-thresholds}),
performance reaches a plateau with no need to further increase the size of the observed subset.

There seems to be a slight increase in population accuracy for small values of N (10, 20) however.
An even larger sample size would probably be needed to decide whether this is randomness or positive interferencce from the unused parts of the reservoir.
Selecting 10 nodes from 100 or 140, of which 50 and 70 respectively rececive input each tick, might result in a heavy bias towards either side.
Further, there is a possibility that slightly better subset performance could have been achieved by generating reservoirs for all ICs instead of using a flat IC of 50\%,
and then selecting the best one.
Even though the average optimal IC is quite close to 50\%,
the backing data may lie slightly to either side,
as seen in table \ref{tab:oc-reservoir-parameters}.

Another concern is in what way, if any, a smaller set of reservoir states affects the model used for learning the mapping from reservoir states to classification.
Using too many predictor variables in a linear model might result in overfitting the problem,
while too few may result in low accuracies.
The problem of redundant or useless variables is lessened if one uses an algorithm which includes regularization,
such as ridge regression \cite{hoerl1970ridge}.
The regularization penalty rewards smaller coefficients which in turn leads to useless variables being eliminated almost completely,
but they cannot be totally zeroed within this model.
Algorithmic regression variable subset selection which completely eliminates unneeded variables exists \cite{miller2002subset},
but may not be useful for systems with a small readout-to-reservoir ratio.
Such a system is the sixty electrodes stuck into a large soup of rat neurons \cite{demarse2005adaptive}.
Any redundancy in the neurons must surely be dominated by the nonlinearity each microelectrode aggregates from all nearby neurons,
reducing the need for variable elimination.

In a continiously growing and expaning reservoir,
such as the one consisting of rat neurons,
the computational capabilities of the system would presumably grow monotonically with the increase in matter to the system.
These results indicate that as long as one has instrumented a large enough part of the resvoir in the first place,
one will not have to re-instrument it in the future (as long as the task doesn't change to a significantly more complex one requiring additional data points).
The readout layer might have to be recalibrated, however.
A regression model trained on a certain reservoir might not work as well on one with a slightly altered topology.
In section \ref{section:pre-thesis-project} it is found that there exists a neutrality in the set of RBN Reservoirs.
That is, if one were to re-use a trained readout layer from a well-performing reservoir,
there will be a number of different RBNs that perform accurately together with the re-used readout layer.
It was not investigated whether these functionally equivalent reservoirs were structurally similar.
If they are, one might not have to retrain the model every time the substrate evolves,
as small changes to the topology might jump to a similarly well-performing RBN due to the inherent neutrality.
