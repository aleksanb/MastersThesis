\chapter{Introduction}

Reservoir Computing (RC) is a category of machine learning that sprang out from the study of recurrent neural networks (RNNs).
In short, it utilizes the dynamics of some complex system dubbed a 'reservoir' to preprocess a timeseries problem,
transforming it from a temporal to a spacial one in the reservoir,
making it separable with a simple readout layer \cite{lukovsevivcius2012reservoir}.

Reservoir Computing can be used both with physical and theoretical reservoirs.
The original theoretical Echo State Networks \cite{jaeger2002adaptive} and Liquid State Machines \cite{natschlager2002liquid} provided the original basis for theoretical Reservoir Computing systems.
As alternative abstractions to RRNs,
both Cellular Automata \cite{yilmaz2014reservoir} and Random Boolean Networks \cite{rbn-reservoir} were introduced and sucessfully used in reservoir computing frameworks.
RBNs \cite{gershenson2004introduction} are an useful abstraction over many physical phenomena,
most famously used by Kauffman \cite{kauffman1969metabolic} as a model for the genetic regulatory network.
In the authors pre-thesis paper,
findings from \cite{rbn-reservoir} were reproduced and the reusability of trained readout layers investigated.
A a neturality in the state-space of possible RBNs was discovered.

Physical reservoirs take many shapes and forms.
In the ever-so-cited 'Pattern recognition in a bucket' paper \cite{fernando2003pattern},
the authors use a bucket of water to successfully perform speech recognition.
In \cite{farstad2015evolving},
a carbon-nanotube based substrate is successfully used to evolve binary logic gates as well as stable Cellular Automata.
These can then be used to build a CA-based computing paradigm over this unconventional hardware.
As Cellular Automata are a special case of Random Boolean Networks,
any general findings about RBN RC systems may be applicable to RC systems using CAs.
The wider category of attempting to harness the power of unconventional physical devices for computation,
usually aided by artificial evolution,
is known as evolution-in-materio \cite{miller2002evolution}.

When using nontraditional physical devices for computation, as in evolution-in-materio,
one is often restricted in how one can perturb and read out the underlying substrate.
It might be prohibitively expensive or technologically infeasible to read the entire state of the reservoir,
and the values sampled might be affected by its neighborhood in unknown ways to us.
In \cite{demarse2005adaptive} the authors use living rat neurons in a microelectrode array to control an airplane in a flight simulator.
Only subsets of the computational substrate are used,
and the neuronal connections even change over time.
In addition, the microelectrode array presents a limited resolution view of the computational substrate.
Questions include how the unused parts of the reservoir impact the parts used for computation,
and how large the reservoir actually needs to be to solve the task at hand.

It has been shown that Reservoir Computing using Random Boolean Networks is a feasible approach to solving binary time-series problems,
as well as being a potentially useful abstraction over physical Reservoir Computing devices.
In this thesis, the properties of these RRC systems are further investigated,
with the motivation of using the results as a template for instrumenting and performing computations on physical Reservoir Computing systems.

The following questions will be answered in this thesis:
\begin{enumerate}
    \item How small can a RRC system be while still solving its task at $ \geq 98\% $Â accuracy?
    \item Does the optimal amount of reservoir perturbation depend on the task at hand?
    \item Does one have to read the state of the entire reservoir to maintain task accuracy?
    \item Is there a correlation between the topological characteristics of the RBN (number of attractors, attractor length) and its performance as a reservoir?
\end{enumerate}

Questions two and three are of specific interest to the implementation of physical reservoirs and evolution-in-materio devices.
What these approaches have in common is that physical substrates,
with varying degrees of perturbation ability and insight into the internal state,
are used for computation.
Their couplings to theoretical frameworks such as Reservoir Computing motivate the exploration of the effects of limited perturbation and readout possibilities on reservoir performance.

\section{Thesis structure}

The thesis is structured as follows:
Chapter \ref{chapter:background} provides background information on reservoir computing, random boolean networks, evo-materio, and using RBNs for Reservoir Computing.
Chapter \ref{chapter:methodology} describes the experimental setup and methodology used for performing experiments.
Chapter \ref{chapter:experiments} contains an in-depth descriptions of each experiment,
the results obtained, and a discussion thereof.
Chapter \ref{chapter:conclusion} concludes the thesis and mentions further work.
